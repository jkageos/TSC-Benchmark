dataset_overrides:
  Beef:
    models:
      cats:
        d_model: 128
        num_heads: 4
        num_layers: 2
      fcn:
        dropout_rate: 0.2
      transformer:
        d_model: 128
        num_heads: 4
        num_layers: 2
  CinCECGTorso:
    models:
      patchtst:
        patch_len: 32
        stride: 16
  KeplerLightCurves:
    batch_size: 32
    epochs: 40
    max_length: 512
    patience: 8
    skip_models: []
datasets:
- Adiac
- ArrowHead
- Beef
- Car
- ChlorineConcentration
- CinCECGTorso
- FiftyWords
- HouseTwenty
- KeplerLightCurves
models:
  autoformer:
    d_ff: 512
    d_model: 128
    dropout: 0.1
    factor: 1
    max_seq_len: 5000
    num_heads: 4
    num_layers: 2
  cats:
    d_ff: 768
    d_model: 192
    dropout: 0.1
    max_seq_len: 5000
    num_heads: 6
    num_layers: 3
  cnn:
    dropout_rate: 0.2
    kernel_size: 3
    num_filters:
    - 64
    - 128
    - 256
  fcn:
    dropout_rate: 0.3
    hidden_dims:
    - 1024
    - 512
    - 256
    - 128
    use_batch_norm: true
  patchtst:
    d_ff: 640
    d_model: 160
    dropout: 0.1
    num_heads: 5
    num_layers: 3
    patch_len: 16
    stride: 8
  transformer:
    d_ff: 768
    d_model: 192
    dropout: 0.1
    max_seq_len: 5000
    num_heads: 6
    num_layers: 3
results:
  output_dir: results
  save_checkpoints: true
  save_history: true
seed: 42
training:
  augmentation_params:
    jitter_strength: 0.03
    prob: 0.5
    scale_range:
    - 0.8
    - 1.2
  batch_size: 64
  device: cuda
  epochs: 100
  gradient_clip: 1.0
  learning_rate: 0.001
  max_length: null
  normalize: true
  optimizer: adamw
  optimizer_params:
    betas:
    - 0.9
    - 0.999
    weight_decay: 0.0001
  padding: repeat
  patience: 15
  swa_start_epoch: 60
  tta_augmentations: 5
  use_amp: true
  use_augmentation: true
  use_compile: true
  use_scheduler: true
  use_swa: true
  use_tta: true
  warmup_epochs: 5
