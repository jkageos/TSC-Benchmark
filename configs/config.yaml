# TSC-Benchmark Configuration

# Execution mode and behavior
execution:
  mode: "benchmark"  # Options: benchmark, test, tune, single
  verbose: true
  # Test mode settings
  test_model: "fcn"
  test_dataset: "Beef"
  # Tune mode settings
  tune_rounds: 2
  # Single mode settings
  single_model: "fcn"
  single_dataset: "CinCECGTorso"

# Target datasets for benchmarking
datasets:
  - "Adiac"
  - "ArrowHead"
  - "Beef"
  - "Car"
  - "ChlorineConcentration"
  - "CinCECGTorso"
  - "FiftyWords"
  - "HouseTwenty"
  - "KeplerLightCurves"

# Hardware and system resource management
hardware:
  device: "cuda"
  compile_mode: "reduce-overhead"
  use_amp: true
  use_compile: false
  max_cpu_load: 0.6
  reserve_cores: 2
  max_workers_override: 4
  auto_workers: true

# Training hyperparameters
training:
  epochs: 100
  batch_size: 48
  learning_rate: 0.001
  optimizer: "adamw"
  optimizer_params:
    weight_decay: 0.01
  patience: 15
  normalize: true
  padding: "zero"
  max_length: null
  num_workers: 0
  use_scheduler: true
  warmup_epochs: 5
  use_augmentation: true
  augmentation_params:
    jitter_strength: 0.03
    scale_range: [0.8, 1.2]
    magnitude_warp_strength: 0.1
    time_warp_strength: 0.1
    prob: 0.5
  use_tta: false
  tta_augmentations: 5
  use_swa: false
  swa_start: 60
  cv_folds: 3

# Model architectures - Memory-optimized
models:
  fcn:
    type: "fcn"
    hidden_dims: [256, 128]
    dropout: 0.3
    use_batch_norm: true

  cnn:
    type: "cnn"
    num_filters: [64, 128, 256]
    kernel_size: 5
    dropout_rate: 0.3

  transformer:
    type: "transformer"
    d_model: 128
    num_heads: 4
    num_layers: 2
    d_ff: 512
    dropout: 0.1
    max_seq_len: 5000

  cats:
    type: "cats"
    d_model: 128
    num_heads: 4
    num_layers: 2
    d_ff: 512
    dropout: 0.1
    max_seq_len: 5000

  autoformer:
    type: "autoformer"
    d_model: 96  # Reduced from 128
    num_heads: 3  # Reduced from 4
    num_layers: 1  # Reduced from 2
    d_ff: 384  # Reduced from 512
    dropout: 0.1
    factor: 1
    max_seq_len: 5000

  patchtst:
    type: "patchtst"
    d_model: 96  # Reduced
    num_heads: 3  # Reduced
    num_layers: 1  # Reduced
    d_ff: 384  # Reduced
    dropout: 0.1
    patch_len: 16
    stride: 8

# Results and logging
results:
  save_dir: "results"
  save_checkpoints: true
  log_interval: 10

# Dataset-specific overrides - Aggressive memory management
dataset_overrides:
  Beef:
    epochs: 80
    batch_size: 8
    patience: 10
    num_workers: 0
  Car:
    epochs: 80
    batch_size: 16
    patience: 10
    num_workers: 0
  ChlorineConcentration:
    batch_size: 16  # Reduced from 32
    max_length: 128  # Aggressive truncation
    num_workers: 0
  FiftyWords:
    epochs: 120
    patience: 20
    batch_size: 16  # Reduced from 32
    max_length: 256
    num_workers: 0
  KeplerLightCurves:
    batch_size: 16  # Reduced from 24
    max_length: 128  # Aggressive truncation
    epochs: 60
    patience: 10
    num_workers: 0
  Adiac:
    batch_size: 16  # Reduced from 32
    max_length: 256  # More aggressive
    num_workers: 0
  CinCECGTorso:
    batch_size: 16  # Reduced from 32
    max_length: 256  # Truncate long sequences
    num_workers: 0
  ArrowHead:
    batch_size: 32
    num_workers: 0
  HouseTwenty:
    batch_size: 16
    epochs: 100
    patience: 15
    num_workers: 0

# Reproducibility
seed: 42
